\documentclass[a4paper,landscape,headrule,footrule]{foils}
%\usepackage{times}
%\usepackage{nttfoilhead}
%\newcommand{\myslide}[1]{\foilhead[-25mm]{\raisebox{12mm}[0mm]{\emp{#1}}}}
%\newcommand{\myslider}[1]{\rotatefoilhead[-25mm]{\raisebox{12mm}[0mm]{\emp{#1}}}}
%\newcommand{\myslider}[1]{\rotatefoilhead{\raisebox{-8mm}{\emp{#1}}}}

\input{headx.tex}



\begin{document}
\header{Lecture 1b}{First attempts at a theory of grammar}{}\maketitle

%\include{schedule}

\myslide{Overview}

\begin{itemize}
\item Two Syntactic Theories that won’t work
\item Context Free Grammars
\item Central claims of CFG
\end{itemize}


\myslide{What makes a good model?}

\begin{itemize}
\item \txx{generative}: license all grammatical sentences and only them
\\ $\Rightarrow$ \txx{precise}
\item \txx{explanatory}: can explain generalizations
  \begin{itemize}
  \item  \eng{the cat chased the rat} $\sim$ \eng{the rat was chased by the cat} \com{semantics}
  \item phrases tend to act like one member of the phrase \com{headedness}
  \item new information tends to come first/last \com{information theory}
  \end{itemize}
\item \txx{concise}: the model is as simple as possible \com{elegant}
\\ $\Rightarrow$ \txx{universal} \com{minimal stipulations}
\item \txx{tractable}: the model can be modeled computationally
\end{itemize}

\begin{center}
  Our models are normally imperfect: \\
we aim for iteratively improved approximations
\end{center}

\myslide{Insufficient Theory \#1}
\begin{itemize}
\item A grammar is simply a list of sentences.
\item What’s wrong with this?
\end{itemize}

\myslide{Insufficient Theory \#2: Regular Expressions}
\begin{exe}
  \ex \gll the noisy dogs left \\
  D A N V \\
  \ex  \gll the noisy dogs chased the innocent cats \\
 D A N V D A N \\
\end{exe}
\begin{itemize}
\item (D) A* N V ((D) A* N)
\end{itemize}
\hrule
\txx{Regular expressions}: a formal language for matching things.
\\[2ex]
 \begin{tabular}{ll}
    Symbol & Matches \\ \hline
    . & any single character\\
%    {[ ]} & a single character that is contained within the brackets. \\
%    & {[a-z]} specifies a range which matches any  letter from "a" to "z".\\
%    {[\textasciicircum ~]} & 	a single character not in the brackets. \\
%    \textasciicircum 	& the starting position within the string/line. \\
%    \$ 	&  the ending position of the string/line. \\
    $*$ &	the preceding element zero or more times. \\
    ? &	 the preceding element zero or one time: OR just () = ()?. \\
    + &	 the preceding element one or more times. \\
    $|$ &  either the expression before or after the operator. \\
%    $\backslash$ & escapes the following character. \\
  \end{tabular}

% \myslide{A Finite State Machine}
% D

% N

% V

% D

% A

% N

% A
% V
% V


%\myslide{FSMs for Grammar, cont}

% \item Why are FSMs insufficient as a

% representation of natural language syntax?

% \item How might they be useful anyway?


% \myslide{Chomsky Hierarchy}
% Type 0 Languages
% Context-Sensitive Languages
% Context-Free Languages
% Regular Languages


\myslide{Context-Free Grammar}
\begin{itemize}
\item A quadruple: $\langle C, V, P, S \rangle$
\begin{itemize}
\item[$C$] set of categories ($\alpha, \beta, \ldots$)
\item[$V$] set of terminals (vocabulary)
\item[$P$] set of rewrite rules $\alpha \into \beta_1, \beta_2, \ldots, \beta_n$
\item[$S$] the start symbol $\mathbf{S} \in C$
\end{itemize}
\item For each rule $\alpha \into \beta_1, \beta_2, \ldots, \beta_n \in P$
  \begin{itemize}
  \item  $\alpha \in C$
  \item  $\beta_i \in C \cup V; 1 \le i \le n$ 
\end{itemize}
\end{itemize}


\myslide{A Toy Grammar}

\begin{itemize}
\item RULES
\\[2ex]  \begin{tabular}{lll}
\textbf{S}  & \into & NP VP \\
NP & \into & (D) A* N PP*\\
VP & \into & V (NP) (PP)\\
PP & \into & P NP\\
\end{tabular}

\item VOCABULARY
\begin{flushleft}
D: the, some\\
A: big, brown, old\\
N: birds, fleas, dog, hunter, I\\
V: attack, ate, watched\\
P: for, beside, with
\end{flushleft}
\end{itemize}

\myslide{Structural Ambiguity}
\begin{center} \large
  \eng{I saw the astronomer with the telescope.}
\end{center}

\myslide{Structure 1: PP under VP}
{%
 \leaf{\emph{I}}
 \branch{1}{N}
 \branch{1}{NP}
 \leaf{\emph{saw}}
 \branch{1}{V}
 \leaf{\emph{the}}
 \branch{1}{D}
 \leaf{\emph{astronomer}}
 \branch{1}{N}
 \branch{2}{NP}
 \leaf{\emph{with}}
 \branch{1}{P}
 \leaf{\emph{the}}
 \branch{1}{D}
 \leaf{\emph{telescope}}
 \branch{1}{N}
 \branch{2}{NP}
 \branch{2}{PP}
 \branch{3}{VP}
 \branch{2}{S}
 \qobitree}

\myslide{Structure 2: PP under NP}
\begin{small} {%
    \leaf{\emph{I}} \branch{1}{N} \branch{1}{NP} \leaf{\emph{saw}}
    \branch{1}{V} \leaf{\emph{the}} \branch{1}{D}
    \leaf{\emph{astronomer}} \branch{1}{N} \leaf{\emph{with}}
    \branch{1}{P} \leaf{\emph{the}} \branch{1}{D}
    \leaf{\emph{telescope}} \branch{1}{N} \branch{2}{NP}
    \branch{2}{PP} \branch{3}{NP} \branch{2}{VP}
    \branch{2}{S} \qobitree}
\end{small}

\myslide{Constituency Tests}
\begin{itemize}\addtolength{\itemsep}{-1ex}
\item Recurrent Patterns
\begin{exe}
\ex \eng{\ul{The quick brown fox with the bushy tail} jumped over \ul{the lazy brown dog
with one ear}.}\
\end{exe}

\item Coordination
\begin{exe}
\ex  \eng{\ul{The quick brown fox with the bushy tail} and \ul{the lazy brown dog with one
ear} are friends.}
\end{exe}
\item Sentence-initial position
\begin{exe}
\ex \eng{\ul{The election of 2000}, everyone will remember for a long time.}
\end{exe}
\item Cleft sentences
\begin{exe}
\ex \eng{It was \ul{a book about syntax} that they were reading.}
\end{exe}
\end{itemize}

\myslide{General Types of Constituency Tests}
\begin{itemize}
\item Distributional
\item Intonational
\item Semantic
\item Psycholinguistic
\item[\ldots] but they don’t always agree.
\end{itemize}

\myslide{Central claims implicit in CFG formalism:}
\begin{enumerate}
\item  Parts of sentences (larger than single words) are
linguistically significant units, i.e. phrases play a role in
determining meaning, pronunciation, and/or the
acceptability of sentences.
\item Phrases are contiguous portions of a sentence (no
discontinuous constituents).
\item Two phrases are either disjoint or one fully contains the
other (no partially overlapping constituents).
\item What a phrase can consist of depends only on what kind of
a phrase it is (that is, the label on its top node), not on what
appears around it.
\end{enumerate}

\newpage
\begin{itemize}
\item Claims 1-3 characterize what is called \txx{phrase structure grammar}

\item Claim 4 (that the internal structure of a phrase depends only on what type of phrase it is, not on where it appears) is what makes it \txx{Context-Free}.

\item \txx{Context-Sensitive Grammar} (CSG) gives up 4. 
That is, it allows the applicability of a
grammar rule to depend on what is in the
neighboring environment. So rules can have the
form: 
\\ $A \into X$ in the context of $\alpha \_\beta$ ($\alpha A\beta \into \alpha X\beta$)
\end{itemize}

\myslide{Possible Counterexamples}
\begin{itemize}
\item To Claim 2 (no discontinuous constituents):
\\ \eng{\ul{A technician} arrived \ul{who could solve the problem}.}

\item To Claim 3 (no overlapping constituents):
\\ \eng{I read \ul{what} was written about me.}

\item To Claim 4 (context independence):
  \begin{exe}
  \ex \eng{He arrives this morning.}
  \ex \eng{*He arrive this morning.}
  \ex \eng{*They arrives this morning.}
  \ex \eng{They arrive this morning.}
  \end{exe}
\end{itemize}


\myslide{Trees and Rules}
  {
 \leaf{$C_1$}
 \leaf{\ldots}
  \leaf{$C_2$}
 \branch{3}{$C_0$} \qobitree}is a well-formed nonlexical tree if (and only if)
\begin{itemize}
\item  $C_0, \ldots,  C_n$ are well-formed trees
\item $C_0$ \into $C_1 \ldots C_n$ is a grammar rule
\end{itemize}

\myslide{Bottom-up Tree Construction}

\begin{flushleft}
D: the \\
V: chased \\
N: dog, cat
\end{flushleft}

{ \leaf{the} \branch{1}{D} \qobitree}
{ \leaf{the} \branch{1}{D} \qobitree}
{ \leaf{chased} \branch{1}{V} \qobitree}
{ \leaf{dog} \branch{1}{N} \qobitree}
{ \leaf{cat} \branch{1}{N} \qobitree}

\begin{tabular}{ccc}
\multicolumn{2}{c}{NP \into D N} & VP \into V NP \\[2ex]

{ \leaf{the} \branch{1}{D}
  \leaf{dog} \branch{1}{N} 
\branch{2}{NP} \qobitree}
&
{ \leaf{the} \branch{1}{D}
  \leaf{cat} \branch{1}{N} 
\branch{2}{NP} \qobitree}
&
{
  \leaf{chased} \branch{1}{V}
    \leaf{the} \branch{1}{D}
    \leaf{cat} \branch{1}{N} 
  \branch{2}{NP}
\branch{2}{VP} \qobitree}
\end{tabular}

\newpage

\begin{tabular}{c}
 S \into NP VP \\[2ex]
{
    \leaf{the} \branch{1}{D}
    \leaf{dog} \branch{1}{N} 
  \branch{2}{NP}
    \leaf{chased} \branch{1}{V}
      \leaf{the} \branch{1}{D}
      \leaf{cat} \branch{1}{N} 
    \branch{2}{NP}
  \branch{2}{VP}
\branch{2}{S} \qobitree}
\end{tabular}

\myslide{Top-down Tree Construction}


\begin{tabular}{cccc}
 S \into NP VP  & VP \into V NP & NP \into D N & NP \into D N \\[2ex]
{ \leaf{NP}
  \leaf{VP}
\branch{2}{S} \qobitree}
&
{ \leaf{V}
  \leaf{NP}
\branch{2}{VP} \qobitree}
&
{ \leaf{D}
  \leaf{N}
\branch{2}{NP} \qobitree}
&
{ \leaf{D}
  \leaf{N}
\branch{2}{NP} \qobitree}
\end{tabular}

{ \leaf{D}
  \leaf{N}
\branch{2}{NP} 
   \leaf{V}
   \leaf{D}
   \leaf{N}
\branch{2}{NP}
\branch{2}{VP}
\branch{2}{S} \qobitree}
{ \leaf{the} \branch{1}{D} \qobitree}
{ \leaf{the} \branch{1}{D} \qobitree}
{ \leaf{chased} \branch{1}{V} \qobitree}
{ \leaf{dog} \branch{1}{N} \qobitree}
{ \leaf{cat} \branch{1}{N} \qobitree}

\begin{tabular}{c}
% Combine \\[2ex]
{
    \leaf{the} \branch{1}{D}
    \leaf{dog} \branch{1}{N} 
  \branch{2}{NP}
    \leaf{chased} \branch{1}{V}
      \leaf{the} \branch{1}{D}
      \leaf{cat} \branch{1}{N} 
    \branch{2}{NP}
  \branch{2}{VP}
\branch{2}{S} \qobitree}
\end{tabular}

\begin{itemize}
\item \txx{Bottom-up}: string \into tree
\item \txx{Top-down}: tree \into string
\item CFG is \txx{declarative} so it is independent of order
\end{itemize}

\myslide{Weaknesses of CFG (atomic node labels)}
\begin{itemize}
\item It doesn’t tell us what constitutes a linguistically
natural rule
\begin{itemize}
\item VP \into P NP
\item NP \into VP S
\end{itemize}
\item Rules get very cumbersome once we try to deal
with things like agreement and transitivity.
\item It has been argued that certain languages (notably
Swiss German and Bambara) contain constructions
that are provably beyond the descriptive capacity of
CFG.
\end{itemize}

\myslide{On the other hand \ldots}

\begin{itemize}
\item It’s a simple formalism that can generate
infinite languages and assign linguistically
plausible structures to them.

\item Linguistic constructions that are beyond the
descriptive power of CFG are rare.

\item It’s computationally tractable and
techniques for processing CFGs are well
understood.
\end{itemize}

\myslide{So \ldots}

\begin{itemize}
\item CFG is the starting point for most
types of generative grammar.

\item The theory we develop in this course is an
extension of CFG.
\end{itemize}

\myslide{Transitivity and Agreement}

\begin{itemize}
\item Consider the following transitivity examples
  \begin{exe}
    \ex \eng{The bird arrives}
    \ex \eng{The bird devours the worm}
    \ex *\eng{The bird arrives the worm}
    \ex *\eng{The bird devours}
  \end{exe}
\item Consider the following agreement examples
  \begin{exe}
    \ex \eng{The bird sings}
    \ex \eng{The birds sing}
    \ex *\eng{The bird sing}
    \ex *\eng{The birds sings}
  \end{exe}
\item Can we deal with them with a CFG?
\end{itemize}

\myslide{Summary}
\begin{enumerate}\addtolength{\itemsep}{-1ex}
\item Fundamentals
\item Investigate
\item Find out some stuff
\item Break our theory
\item Try to fix it.
\item Break it again.
\item Lather, rinse, repeat: we'll do that until we run out of time.
\end{enumerate}

Jorge Hankamer's outline of a syntax course, but it's pretty
applicable to everything we do.  More formally: \emp{Successive Approximation}.


\myslide{Chapter 2, Problem 1}
\begin{tabular}{cc}
  RULES & VOCABULARY \\[2ex]
  \begin{minipage}[t]{0.4\linewidth}
    \begin{tabular}[t]{lll}
      \textbf{S}  & \into & NP VP \\
      NP & \into & (D) NOM\\
      VP & \into & V (NP) (NP)\\
      NOM & \into & N\\
      NOM & \into & NOM PP \\
      VP  & \into & VP PP\\
      PP  & \into & P NP\\
      X   & \into & X+ CONJ X\\
    \end{tabular} 
  \end{minipage} &
  \begin{minipage}[t]{0.5\linewidth}
    \begin{flushleft}
  D: a, the\\
  N: cat, dog, hat, man, woman, roof\\
  V: admired, disappeared, put, relied\\
  P: in, on, with\\
  CONJ: and, or
\end{flushleft}
\end{minipage}
\end{tabular}

\myslide{Chapter 2, Problem 1}

\begin{itemize}
\item [A] Make a well-formed English sentence unambiguous
according to this grammar
\item  [B] Make a well-formed English sentence ambiguous
according to this grammar: draw trees
\item  [C] Make a well-formed English sentence not licensed by
this grammar (using $V$)
\item [D] Why is this (C) not licensed?

\newpage
\item [E] Make a string licensed by this grammar that is not a
  well-formed English sentence
\item [F] How can we stop licensing the string in E (stop over-generating)
\item [G] How many strings does this grammar license?
\item [H] How many strings does this grammar license without conjunctions?
\end{itemize}

\myslide{Shieber 1985}
\begin{itemize}
\item Swiss German example:
  \begin{exe}
    \ex \gll \ldots mer \uline{d’chind} \uuline{em Hans} es \uwave{huus} \uline{l\"ond} \uuline{h\"alfe} \uwave{aastriiche}\\
    \ldots we {the children-acc} Hans-dat the hous-acc let help paint \\
    \trans we let {the children} help Hans paint the house 
  \end{exe}
\item Cross-serial dependency:
\begin{itemize}
\item \eng[let]{l\"ond} governs case on \eng[children]{d’chind}
\item \eng[help]{h\"alfe} governs case on \eng[Hans]{Hans}
\item \eng[paint]{aastriiche} governs case on \eng[house]{huus}
\end{itemize}
\item This cannot be modeled in a context free language
\end{itemize}

\myslide{Strongly/weakly CF}
\begin{itemize}
\item A language is weakly \emp{context-free} if the set of
strings in the language can be generated by a CFG.
\item A language is \emp{strongly} context-free if the CFG
furthermore assigns the correct structures to the
strings.
\item Shieber’s argument is that SW is not \emp{weakly}
context-free and therefore not \emp{strongly} context-free.
\item Bresnan et al (1983) had already argued that Dutch
is \emp{strongly} not context-free, but the argument was
dependent on linguistic analyses.
\end{itemize}

\myslide{Overview}

\begin{itemize}
\item Prescriptive/descriptive grammar;
Competence/performance
\item Some history
\item Why study syntax?
\item Unsuccessful Attempts to model language
\item Formal definition of CFG
  \begin{itemize}
  \item Constituency, ambiguity, constituency tests
  \item Central claims of CFG
  \item Order independence
  \item Weaknesses of CFG
  \end{itemize}
\item Next Week: Feature structures
\end{itemize}


\myslide{Acknowledgments and References}

\begin{itemize}
\item Course design and slides borrow heavily from Emily Bender's course:
\textit{Linguistics 566: Introduction to Syntax for Computational Linguistics}
\\ \url{http://courses.washington.edu/ling566}
\item Thanks to Na-Rae Han for 
  inspiration for the student policies (from  \textit{LING 2050 Special Topics in Linguistics: Corpus linguistics}, U Penn; adapted).
\item Stuart M. Shieber. (1985) Evidence against the context-freeness of natural language. \textit{Linguistics and Philosophy}, 8:333-343
\end{itemize}



\end{document}


%%% Local Variables: 
%%% coding: utf-8
%%% mode: latex
%%% TeX-PDF-mode: t
%%% TeX-engine: xetex
%%% End: 

